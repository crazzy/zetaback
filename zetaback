#!/usr/bin/perl

use strict;
use Getopt::Long;
use MIME::Base64;
use POSIX qw/strftime/;
use Data::Dumper;

use vars qw/$CONF %conf $BLOCKSIZE $DEBUG $HOST $BACKUP $RESTORE
            $LIST $SUMMARY $SUMMARY_EXT
            $EXPUNGE $NUETERED $ZFS/;
$CONF = q^/var/spool/zfs_backups/zetaback.conf^;
$BLOCKSIZE = 1024*64;

$conf{'default'}->{'time_format'} = "%Y-%m-%d %H:%M:%S";
$conf{'default'}->{'retention'} = 14 * 86400;

GetOptions(
  "h=s" => \$HOST,
  "z=s" => \$ZFS,
  "c=s" => \$CONF,
  "b"   => \$BACKUP,
  "l"   => \$LIST,
  "s"   => \$SUMMARY,
  "sx"  => \$SUMMARY_EXT,
  "r"   => \$RESTORE,
  "d"   => \$DEBUG,
  "n"   => \$NUETERED,
  "x"   => \$EXPUNGE,
);

sub parse_config() {
  local($/);
  $/ = undef;
  open(CONF, "<$CONF");
  my $file = <CONF>;
  while($file =~ m/^\s*(\S+)\s\s*{(.*?)}/gms) {
    my $scope = $1;
    my $filepart = $2;
    $conf{$scope} ||= {};
    foreach my $line (split /\n/, $filepart) {
      if($line =~ /^\s*([^#]\S*)\s*=\s*(\S+)/) {
        $conf{$scope}->{lc($1)} = $2;
      }
    }
  }
  close(CONF);
}
sub config_get($$) {
  return $conf{$_[0]}->{$_[1]} || $conf{'default'}->{$_[1]};
}

sub dir_encode($) {
  my $d = shift;
  my $e = encode_base64($d, '');
  $e =~ s/\//_/;
  return $e;
}
sub dir_decode($) {
  my $e = shift;
  $e =~ s/_/\//;
  return decode_base64($e);
}
sub pretty_size($) {
  my $bytes = shift;
  if($bytes > 1024*1024*1024) {
    return sprintf("%0.2f Gb", $bytes / (1024*1024*1024));
  }
  if($bytes > 1024*1024) {
    return sprintf("%0.2f Mb", $bytes / (1024*1024));
  }
  if($bytes > 1024) {
    return sprintf("%0.2f Kb", $bytes / (1024));
  }
  return "$bytes b";
}
sub scan_for_backups($) {
  my %info = ();
  my $dir = shift;
  $info{last_full} = $info{last_incremental} = $info{last_backup} = 0;
  opendir(D, $dir) || return \%info;
  foreach my $file (readdir(D)) {
    if($file =~ /^(\d+)\.([^\.]+)\.full$/) {
      my $whence = $1;
      my $fs = dir_decode($2);
      $info{$fs}->{full}->{$whence}->{'file'} = "$dir/$file";
      $info{$fs}->{last_full} = $whence if($whence > $info{$fs}->{last_full});
      $info{$fs}->{last_backup} = $info{$fs}->{last_incremental} > $info{$fs}->{last_full} ?
                                     $info{$fs}->{last_incremental} : $info{$fs}->{last_full};
    }
    elsif($file =~ /^(\d+).([^\.]+)\.incremental.(\d+)$/) {
      my $whence = $1;
      my $fs = dir_decode($2);
      $info{$fs}->{incremental}->{$whence}->{'depends'} = $3;
      $info{$fs}->{incremental}->{$whence}->{'file'} = "$dir/$file";
      $info{$fs}->{last_incremental} = $whence if($whence > $info{$fs}->{last_incremental});
      $info{$fs}->{last_backup} = $info{$fs}->{last_incremental} > $info{$fs}->{last_full} ?
                                     $info{$fs}->{last_incremental} : $info{$fs}->{last_full};
    }
  }
  closedir(D);
  return \%info;
}

parse_config();

sub zfs_remove_snap($$$) {
  my ($host, $fs, $snap) = @_;
  my $agent = config_get($host, 'agent');
  return unless($snap);
  print "Dropping $snap on $fs\n" if($DEBUG);
  `ssh $host $agent -z $fs -d $snap`;
}

# Lots of args.. internally called.
sub zfs_do_backup($$$$$$) {
  my ($host, $fs, $type, $point, $store, $dumpfile) = @_;
  my $agent = config_get($host, 'agent');

  # Do it. yeah.
  open(LBACKUP, ">$store/.$dumpfile") || die "zfs_full_backup: cannot create dump\n";
  eval {
    open(RBACKUP, "ssh $host $agent -z $fs -$type $point |") || die "zfs_full_backup: cannot perform send\n";
    my $buffer;
    while(my $len = sysread(RBACKUP, $buffer, $BLOCKSIZE)) {
      if(syswrite(LBACKUP, $buffer, $len) != $len) {
        die "$!";
      }
    }
    close(LBACKUP);
    close(RBACKUP);
    die "dump failed (zero bytes)\n" if(-z "$store/.$dumpfile");
    rename("$store/.$dumpfile", "$store/$dumpfile") || die "cannot rename dump\n";
  };
  if($@) {
    unlink("$store/.$dumpfile");
    die "zfs_full_backup: failed $@";
  }
}

sub zfs_full_backup($$$) {
  my ($host, $fs, $store) = @_;

  # Translate into a proper dumpfile nameA
  my $point = time();
  my $efs = dir_encode($fs);
  my $dumpfile = "$point.$efs.full";

  zfs_do_backup($host, $fs, 'f', $point, $store, $dumpfile);
}

sub zfs_incremental_backup($$$$) {
  my ($host, $fs, $base, $store) = @_;
  my $agent = config_get($host, 'agent');

  # Translate into a proper dumpfile nameA
  my $point = time();
  my $efs = dir_encode($fs);
  my $dumpfile = "$point.$efs.incremental.$base";

  zfs_do_backup($host, $fs, 'i', $base, $store, $dumpfile);
}

sub perform_retention($$) {
  my ($host, $store) = @_;
  my $cutoff = time() - config_get($host, 'retention');
  my $backup_info = scan_for_backups($store);
  
  foreach my $disk (sort keys %{$backup_info}) {
    my $info = $backup_info->{$disk};
    next unless(ref($info) eq 'HASH');
    my %must_save;

    # Get a list of all the full and incrementals, sorts newest to oldest
    my @backup_points = (keys %{$info->{full}}, keys %{$info->{incremental}});
    @backup_points = sort { $b <=> $a } @backup_points;

    # We _cannot_ throw away _all_ out backups, so save the most recent no matter what
    $must_save{$backup_points[0]} = 1;

    # Walk the list for backups within our retention period.
    foreach (@backup_points) {
      if($_ >= $cutoff) {
        $must_save{$_} = 1;
      }
      else {
        # they are in decending order, once we miss, all will miss
        last;
      }
    }

    # Look for dependencies
    foreach (@backup_points) {
      if(exists($info->{incremental}->{$_})) {
        print "   => $_ depends on $info->{incremental}->{$_}->{depends}\n" if($DEBUG);
        $must_save{$info->{incremental}->{$_}} = 1
      }
    }
    my @removals = grep { !exists($must_save{$_}) } @backup_points;
    if($DEBUG) {
      my $tf = config_get($host, 'time_format');
      print "    => I can remove:\n";
      foreach (@backup_points) {
        print "      => ". strftime($tf, localtime($_));
        print " [". (exists($info->{full}->{$_}) ? "full":"incremental") ."]";
        print " XXX" if(!exists($must_save{$_}));
        print "\n";
      }
    }
    foreach (@removals) {
      my $efs = dir_encode($disk);
      my $filename;
      if(exists($info->{full}->{$_})) {
        $filename = "$store/$_.$efs.full";
      }
      elsif(exists($info->{incremental}->{$_})) {
        $filename = "$store/$_.$efs.incremental.$info->{incremental}->{$_}->{depends}";
      }
      else {
        print "ERROR: We tried to expunge $host $disk [$_], but couldn't find it.\n";
      }
      print "    => expunging $filename\n" if($DEBUG);
      unless($NUETERED) {
        unlink($filename) || print "ERROR: unlink $filename: $?\n";
      }
    }
  }
}

sub show_backups($$$) {
  my ($host, $store, $diskpat) = @_;
  my $backup_info = scan_for_backups($store);
  my $tf = config_get($host, 'time_format');
  foreach my $disk (sort keys %{$backup_info}) {
    my $info = $backup_info->{$disk};
    next unless(ref($info) eq 'HASH');
    next
      if($diskpat &&      # if the pattern was specified it could
         !($disk eq $diskpat ||        # be a specific match or a
           ($diskpat =~ /^\/(.+)\/$/ && $disk =~ /$1/))); # regex
    # We want to see this one
    print "$host:$disk\n";
    next unless($SUMMARY || $SUMMARY_EXT);
    if($SUMMARY_EXT) {
      print "\tLast Full: ". ($info->{last_full} ? strftime($tf, localtime($info->{last_full})) : "Never") . "\n";
      if($info->{last_full} < $info->{last_incremental}) {
        print "\tLast Incr: ". strftime($tf, localtime($info->{last_incremental})). "\n";
      }
    }
    my @backup_points = (keys %{$info->{full}}, keys %{$info->{incremental}});
    @backup_points = sort { $a <=> $b } @backup_points;
    unless ($SUMMARY_EXT) {
      @backup_points = (pop @backup_points);
    }
    foreach (@backup_points) {
      print "\t" . strftime($tf, localtime($_)) . " [$_] ";
      if(exists($info->{full}->{$_})) {
        my @st = stat($info->{full}->{$_}->{file});
        print "FULL " . pretty_size($st[7]);
      } else {
        my @st = stat($info->{incremental}->{$_}->{file});
        print "INCR from [$info->{incremental}->{$_}->{depends}] " . pretty_size($st[7]);
      }
      print "\n";
    }
    print "\n";
  }
}

sub plan_and_run($$$) {
  my ($host, $store, $diskpat) = @_;
  print "Planning '$host'\n" if($DEBUG);
  my $agent = config_get($host, 'agent');
  open(ZFSLIST, "ssh $host $agent -l |") || next;
  foreach my $diskline (<ZFSLIST>) {
    chomp($diskline);
    next unless($diskline =~ /^(\S+) \[([^\]]*)\]/);
    my $diskname = $1;
    my %snaps;
    map { $snaps{$_} = 1 } (split(/,/, $2));

    # If we are being selective (via -z) now is the time.
    next
      if($diskpat &&          # if the pattern was specified it could
         !($diskname eq $diskpat ||        # be a specific match or a
           ($diskpat =~ /^\/(.+)\/$/ && $diskname =~ /$1/))); # regex

    print " => Scanning '$store' for old backups of '$diskname'.\n" if($DEBUG);
    # Make directory on demand
    my $backup_info = scan_for_backups($store);
    # That gave us info on all backups, we just want this disk
    $backup_info = $backup_info->{$diskname} || {};

    # Should we do a backup?
    my $backup_type = 'no';
    if(time() > $backup_info->{last_backup} + config_get($host, 'backup_interval')) {
      $backup_type = 'incremental';
    }
    if(time() > $backup_info->{last_full} + config_get($host, 'full_interval')) {
      $backup_type = 'full';
    }

    # If we want an incremental, but have no full, then we need to upgrade to full
    if($backup_type eq 'incremental') {
      my $have_full_locally = 0;
      # For each local full backup, see if the full backup still exists on the other end.
      foreach (keys %{$backup_info->{'full'}}) {
        $have_full_locally = 1 if(exists($snaps{'__zb_full_' . $_}));
      }
      $backup_type = 'full' unless($have_full_locally);
    }

    print " => doing $backup_type backup\n" if($DEBUG);
    # We need to drop a __zb_base snap or a __zb_incr snap before we proceed
    unless($NUETERED) {
      if($backup_type eq 'full') {
        eval { zfs_full_backup($host, $diskname, $store); };
        if ($@) {
          chomp(my $err = $@);
          print " => failure $err\n";
        }
        else {
          # Unless there was an error backing up, remove all the other full snaps
          foreach (keys %snaps) {
            zfs_remove_snap($host, $diskname, $_) if(/^__zb_full_(\d+)/) 
          }
        }
      }
      if($backup_type eq 'incremental') {
        zfs_remove_snap($host, $diskname, '__zb_incr') if($snaps{'__zb_incr'});
        # Find the newest full from which to do an incremental (NOTE: reverse numeric sort)
        my @fulls = sort { $b <=> $a } (keys %{$backup_info->{'full'}});
        zfs_incremental_backup($host, $diskname, $fulls[0], $store);
      }
    }
  }
  close(ZFSLIST);
}

foreach my $host (grep { $_ ne "default" } keys %conf) {
  # If -h was specific, we will skip this host if the arg isn't
  # an exact match or a pattern match
  if($HOST &&
     !(($HOST eq $host) ||
       ($HOST =~ /^\/(.*)\/$/ && $host =~ /$1/))) {
    next;
  }

  my $store = config_get($host, 'store');
  $store =~ s/%h/$host/g;;
  mkdir $store if(! -d $store);

  if($BACKUP) {
    plan_and_run($host, $store, $ZFS);
  }
  if($LIST || $SUMMARY || $SUMMARY_EXT) {
    show_backups($host, $store, $ZFS);
  }
  if($EXPUNGE) {
    perform_retention($host, $store);
  }
}

